{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tillo/Repositorys/stock-price-rnn\n",
      "/Users/tillo/Repositorys/stock-price-rnn/data/processed\n",
      "/Users/tillo/Repositorys/stock-price-rnn/data/raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time \n",
    "import sys\n",
    "\n",
    "# For saving it as a csv file \n",
    "import pandas as pd \n",
    "\n",
    "# Add the src directory to the system path\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if src_path not in sys.path: sys.path.append(src_path)\n",
    "# Import your fetch function\n",
    "from utils import *\n",
    "\n",
    "# Lösung für Notebooks: \n",
    "# In Jupyter: Arbeitsverzeichnis (z. B. Projektordner)\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "# Path wo die roh daten gespeichert sind \n",
    "path_data_raw       = project_root / \"data\" / \"raw\"\n",
    "# Path wo die processed data gespeichert wird \n",
    "path_data_processed = project_root / \"data\" / \"processed\"\n",
    "# Path wo die processed data gespeichert wird \n",
    "path_plots           = project_root / \"reports\" / \"plots\"\n",
    "\n",
    "\n",
    "print(project_root)\n",
    "print(path_data_processed)\n",
    "print(path_data_raw)\n",
    "\n",
    "# Pfade sicherstellen für die process data files und fuer die plot files im reports Folder \n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"reports/plots\").mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_googl_last_1000_days', 'df_mbg.dex_last_1000_days', 'df_aapl_last_1000_days', 'df_msft_last_1000_days'])\n",
      "df_googl_last_1000_days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Lösung nur für Python Scripte weil hier __file__ erkannt wird \n",
    "project_root = Path(__file__).resolve().parents[1]\n",
    "\n",
    "data_folder = Path(__file__).resolve().parents[1] / \"data\" / \"raw\"\n",
    "\n",
    "    # Create folder if it doesn't exist\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Finde alle CSV-Dateien\n",
    "csv_files = list_csv_files(path_data_raw)\n",
    "\n",
    "#print(data_folder)\n",
    "#print(csv_files)\n",
    "\n",
    "# Lade sie in ein Dictionary mit DataFrames\n",
    "dfs = load_csvs_as_dfs(csv_files, path_data_raw)\n",
    "\n",
    "# Zugriff auf einen bestimmten DataFrame:\n",
    "print(dfs.keys())  # z. B. df_apple_stock, df_dax_2020 etc.\n",
    "\n",
    "# Erstellen einer liste der keys der aktien \n",
    "keys_list = list(dfs.keys())\n",
    "print(keys_list[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitung abgeschlossen für: ['df_googl_last_1000_days', 'df_mbg.dex_last_1000_days', 'df_aapl_last_1000_days', 'df_msft_last_1000_days']\n"
     ]
    }
   ],
   "source": [
    "processed_dfs = {}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    df = add_moving_average(df)\n",
    "    df = add_ema(df)\n",
    "    df = add_lowess(df)\n",
    "    df = add_savgol_filter(df)\n",
    "    df = add_local_peaks(df, distance=50)\n",
    "    df = add_local_valleys(df, distance=50)\n",
    "    df = decompose_seasonality(df)\n",
    "    df = analyze_volume_peaks(df)\n",
    "\n",
    "\n",
    "    # Neue einzel Pfade definieren\n",
    "    plot = path_plots / f\"{name}.png\"\n",
    "    data = path_data_processed / f\"{name}.csv\"\n",
    "\n",
    "    # Plot und speichern\n",
    "    plot_price_with_indicators(df, symbol=name, save_path=plot, show=False)\n",
    "    plot_trend_seasonal_resid(df, symbol=name, save_path=plot, show=False)\n",
    "\n",
    "    # Daten speichern\n",
    "    df.to_csv(data, index=True)\n",
    "    \n",
    "    processed_dfs[name] = df\n",
    "\n",
    "\n",
    "print(\"Verarbeitung abgeschlossen für:\", list(processed_dfs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma_20</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>lowess</th>\n",
       "      <th>savgol</th>\n",
       "      <th>is_peak</th>\n",
       "      <th>is_valley</th>\n",
       "      <th>trend</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>resid</th>\n",
       "      <th>volume_sma_20</th>\n",
       "      <th>high_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-06</th>\n",
       "      <td>140.070</td>\n",
       "      <td>143.15</td>\n",
       "      <td>140.0700</td>\n",
       "      <td>142.02</td>\n",
       "      <td>108181793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.020000</td>\n",
       "      <td>144.564033</td>\n",
       "      <td>143.162349</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>156.978788</td>\n",
       "      <td>-14.550177</td>\n",
       "      <td>-0.408611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07</th>\n",
       "      <td>143.535</td>\n",
       "      <td>144.89</td>\n",
       "      <td>142.6600</td>\n",
       "      <td>144.57</td>\n",
       "      <td>104911589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.262857</td>\n",
       "      <td>144.650988</td>\n",
       "      <td>143.723177</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>156.985385</td>\n",
       "      <td>-12.329170</td>\n",
       "      <td>-0.086215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>141.580</td>\n",
       "      <td>144.06</td>\n",
       "      <td>140.6650</td>\n",
       "      <td>143.24</td>\n",
       "      <td>105575458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.355918</td>\n",
       "      <td>144.737971</td>\n",
       "      <td>144.238438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>156.991986</td>\n",
       "      <td>-13.401721</td>\n",
       "      <td>-0.350264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>142.750</td>\n",
       "      <td>145.65</td>\n",
       "      <td>142.6522</td>\n",
       "      <td>145.11</td>\n",
       "      <td>99890800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.618212</td>\n",
       "      <td>144.825031</td>\n",
       "      <td>144.708133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>156.998591</td>\n",
       "      <td>-11.593050</td>\n",
       "      <td>-0.295540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12</th>\n",
       "      <td>146.210</td>\n",
       "      <td>146.32</td>\n",
       "      <td>144.0000</td>\n",
       "      <td>144.50</td>\n",
       "      <td>76299719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.797430</td>\n",
       "      <td>145.087333</td>\n",
       "      <td>145.132262</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>157.005201</td>\n",
       "      <td>-12.327016</td>\n",
       "      <td>-0.178185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open    high       low   close     volume  sma_20      ema_20  \\\n",
       "Date                                                                           \n",
       "2021-07-06  140.070  143.15  140.0700  142.02  108181793     NaN  142.020000   \n",
       "2021-07-07  143.535  144.89  142.6600  144.57  104911589     NaN  142.262857   \n",
       "2021-07-08  141.580  144.06  140.6650  143.24  105575458     NaN  142.355918   \n",
       "2021-07-09  142.750  145.65  142.6522  145.11   99890800     NaN  142.618212   \n",
       "2021-07-12  146.210  146.32  144.0000  144.50   76299719     NaN  142.797430   \n",
       "\n",
       "                lowess      savgol  is_peak  is_valley       trend   seasonal  \\\n",
       "Date                                                                            \n",
       "2021-07-06  144.564033  143.162349    False      False  156.978788 -14.550177   \n",
       "2021-07-07  144.650988  143.723177    False      False  156.985385 -12.329170   \n",
       "2021-07-08  144.737971  144.238438    False      False  156.991986 -13.401721   \n",
       "2021-07-09  144.825031  144.708133    False      False  156.998591 -11.593050   \n",
       "2021-07-12  145.087333  145.132262    False      False  157.005201 -12.327016   \n",
       "\n",
       "               resid  volume_sma_20  high_volume  \n",
       "Date                                              \n",
       "2021-07-06 -0.408611            NaN        False  \n",
       "2021-07-07 -0.086215            NaN        False  \n",
       "2021-07-08 -0.350264            NaN        False  \n",
       "2021-07-09 -0.295540            NaN        False  \n",
       "2021-07-12 -0.178185            NaN        False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test df für prediction with time series model \n",
    "df_test = processed_dfs['df_aapl_last_1000_days']\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ARMA-Modell (AR=2, MA=2)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mARIMA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# d=0 → stationäre Zeitreihe\u001b[39;00m\n\u001b[1;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prognose ausgeben\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/tsa/arima/model.py:158\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    151\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the specification\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# (don't pass specific values of enforce stationarity/invertibility,\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# because we don't actually want to restrict the estimators based on\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# this criteria. Instead, we'll just make sure that the parameter\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# estimates from those methods satisfy the criteria.)\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAXSpecification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcentrate_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentrate_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_specification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_specification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39morig_exog\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Raise an error if we have a constant in an integrated model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/tsa/arima/specification.py:446\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    441\u001b[0m         exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[trend_data, exog]\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Create an underlying time series model, to handle endog / exog,\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# especially validating shapes, retrieving names, and potentially\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# providing us with a time series index\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mendog\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:470\u001b[0m, in \u001b[0;36mTimeSeriesModel.__init__\u001b[0;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    469\u001b[0m ):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# Date handling in indexes\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_dates(dates, freq)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DS/lib/python3.11/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# Umgang mit unterschiedlichen Zeitreihen und anwendung von\n",
    "# ARMA; ARIMA oder SARIMA Modell\n",
    "################ ARMA #################\n",
    "#### ist eigentlich eine ARIMA modell mit d=o\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# ARMA-Modell (AR=2, MA=2)\n",
    "model = ARIMA(df_test, order=(2, 0, 2)) # d=0 → stationäre Zeitreihe\n",
    "result = model.fit()\n",
    "# Prognose ausgeben\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ ARIMA #################\n",
    "# ARIMA-Modell (AR=2, I=1, MA=2) → 1-fache Differenzierung für Stationarität\n",
    "model = ARIMA(data, order=(2, 1, 2))\n",
    "result = model.fit()\n",
    "# Vorhersagen für die nächsten 12 Zeitpunkte\n",
    "forecast = result.forecast(steps=12)\n",
    "print(forecast)\n",
    "################ SARIMA #################\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# SARIMA-Modell (z. B. mit jährlicher Saisonalität für Monatsdaten)\n",
    "model = SARIMAX(data, order=(2, 1, 2), seasonal_order=(1, 1, 1, 12))\n",
    "result = model.fit()\n",
    "# Vorhersage für die nächsten 12 Monate\n",
    "forecast = result.get_forecast(steps=12)\n",
    "print(forecast.predicted_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "die nächsten möglichen schritte: \n",
    "\n",
    "1. Grundlegende statistische Kennzahlen berechnen\n",
    "Mittelwerte (Mean) z.B. für close-Preise über einen Zeitraum (Tag, Woche, Monat)\n",
    "\n",
    "Median, Standardabweichung, Varianz — um die Volatilität einzuschätzen\n",
    "\n",
    "2. Gleitende Durchschnitte (Moving Averages)\n",
    "Berechnung von gleitenden Durchschnitten wie dem Simple Moving Average (SMA) oder Exponential Moving Average (EMA)\n",
    "\n",
    "Hilft, Trends zu glätten und rauschen zu reduzieren\n",
    "\n",
    "3. Glättung der Kurve\n",
    "Mit Moving Averages oder Lowess-Glättung (LOcally WEighted Scatterplot Smoothing)\n",
    "\n",
    "Alternativ auch mit Savitzky-Golay-Filter\n",
    "\n",
    "4. Lokale Maxima und Minima finden\n",
    "Suche nach Hochs und Tiefs in der Zeitreihe, z.B. mit scipy.signal.find_peaks\n",
    "\n",
    "Definiere Abstand oder Minimum-Distanz (z.B. 1 Monat = ca. 20 Börsentage) zwischen Peaks\n",
    "\n",
    "Erkenne Unterstützungs- und Widerstandslinien\n",
    "\n",
    "5. Saisonale Muster und Zeitreihenanalyse\n",
    "Analyse mit Rolling Windows oder Seasonal Decomposition (z.B. STL-Decomposition)\n",
    "\n",
    "Untersuchung von Trends, Saisonalität, Residuen\n",
    "\n",
    "Beispiel: Hat der Kurs z.B. immer im Januar einen Anstieg?\n",
    "\n",
    "6. Volumen-Analyse\n",
    "Analyse des Handelsvolumens in Kombination mit Kursbewegungen (z.B. Volumen bei Hochs und Tiefs)\n",
    "\n",
    "7. Visualisierung\n",
    "Plotten der Rohdaten, Moving Averages, Peaks/Valleys, Saisonalität\n",
    "\n",
    "Plot mit matplotlib, seaborn oder plotly\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
